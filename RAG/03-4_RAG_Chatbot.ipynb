{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f63c1c",
   "metadata": {},
   "source": [
    "## RAG 기반 Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4fed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 라이브러리 import (모든 import를 상단에 모음)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # 최신 import 방식\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e1a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 환경 변수 로드 및 API 키 설정\n",
    "load_dotenv()  # .env 파일에서 환경변수 로드\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5d3f3-4f07-4995-91ca-a9d36207114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 로드 완료: 7개 페이지\n"
     ]
    }
   ],
   "source": [
    "# 3. PDF 문서 로드\n",
    "pdf_filepath = './data/소나기.pdf'\n",
    "loader = ...  # ... code here\n",
    "data = ...    \n",
    "print(f\"PDF 로드 완료: {len(data)}개 페이지\")# ... code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2890adf-3476-4706-9685-27d8b90668ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 분할 완료: 7개 청크\n"
     ]
    }
   ],
   "source": [
    "# 4. 텍스트 분할 (청킹)\n",
    "text_splitter = ... (  # ... code here\n",
    "    chunk_size=1000,    # 청크 크기: 1000자\n",
    "    chunk_overlap=200   # 청크 간 겹침: 200자\n",
    ")\n",
    "data = ...(data)  # ... code here\n",
    "print(f\"텍스트 분할 완료: {len(data)}개 청크\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f96ef4-372c-4313-bd1f-26a854898794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. OpenAI 임베딩 모델 초기화\n",
    "embeddings = ... (  # ... code here\n",
    "    model=\"text-embedding-ada-002\", \n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8a7cd-9f6b-47cd-9b6f-a58d07fabb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. FAISS 벡터스토어 생성 (문서를 벡터로 변환하여 저장) : Document 객체 리스트 입력 (chunk된 거)\n",
    "vectorstore = ... (data, embeddings)  # ... code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b82ae3e-0788-41d5-b666-2c2f308dc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. ChatGPT 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    api_key=api_key,\n",
    "    temperature=0  # 일관된 답변을 위해 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96aaf68-c29d-4e62-a8ac-91e9a1faa56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 대화 메모리 설정 (이전 대화 내용 기억)\n",
    "memory = ... (  # ... code here\n",
    "    memory_key='chat_history',  # 메모리 키 설정\n",
    "    return_messages=True        # 메시지 형태로 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb20fe3-336d-4324-9c8c-08b7aaadcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 대화형 검색 체인 생성 (RAG + 대화 기능) - ConversationalRetrievalChain 사용\n",
    "conversation_chain = ... (  # ... code here\n",
    "    llm=llm,                                    # 사용할 LLM 모델\n",
    "    chain_type=\"...\",      # ... code here      # 문서 처리 방식 : 문서를 한꺼번에 넘기는 방식\n",
    "    retriever=...,        # ... code here       # 벡터 검색기\n",
    "    memory=memory                               # 대화 메모리\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9c0cd-aafd-49ed-8e68-b51333dfb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문 1: 소년은 어디에서 처음 소녀를 만났나?\n",
      "답변 1: 소년은 처음으로 소녀를 개울가에서 만났습니다.\n"
     ]
    }
   ],
   "source": [
    "# 10. 첫 번째 질문 실행\n",
    "query1 = \"소년은 어디에서 처음 소녀를 만났나?\"\n",
    "print(f\"\\n질문 1: {query1}\")\n",
    "\n",
    "result1 = ... ({\"question\": query1})    # ... code here \n",
    "answer1 = result1[\"answer\"]\n",
    "print(f\"답변 1: {answer1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a803cc0-c60f-460d-a116-df27bf6f5cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문 2: 소년은 소녀에게 무엇을 주려고 했나?\n",
      "답변 2: 소년은 소녀에게 대추를 주려고 했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 11. 두 번째 질문 실행 (이전 대화 맥락 유지)\n",
    "query2 = \"소년은 소녀에게 무엇을 주려고 했나?\"\n",
    "print(f\"\\n질문 2: {query2}\")\n",
    "\n",
    "result2 = conversation_chain.invoke({\"question\": query2})  # invoke 사용\n",
    "answer2 = result2[\"answer\"]\n",
    "print(f\"답변 2: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a708f-9cd1-4ae4-a9e9-8424746be80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 질문: 소년은 어디에서 처음 소녀를 만났나?\n",
      " 답변: 소년은 처음으로 소녀를 개울가에서 만났습니다.\n",
      "----------------------------------------\n",
      "\n",
      " 질문: 소년은 소녀에게 무엇을 주려고 했나?\n",
      " 답변: 소년은 소녀에게 대추를 주려고 했습니다.\n",
      "----------------------------------------\n",
      "\n",
      " 질문: 그 장소는 어떤 특징이 있었나?\n",
      " 답변: 해당 장면은 개울가와 징검다리가 중심에 있었던 것으로 보입니다. 소년과 소녀가 만나고 대화를 나누는 장면에서 주변 환경과 자연의 아름다움이 묘사되었습니다. 또한, 주변에는 갈밭과 메밀밭, 허수아비 등의 풍경이 묘사되어 있습니다.\n",
      "----------------------------------------\n",
      "\n",
      " 질문: 소나기는 언제 내렸나?\n",
      " 답변: 소나기는 주어진 텍스트에서 언급되지 않았습니다. 따라서 소나기가 언제 내렸는지에 대한 정보는 제공할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의응답 함수로 만들기 (재사용 가능)\n",
    "def ask_question(chain, question):\n",
    "    \"\"\"질문을 하고 답변을 받는 함수\"\"\"\n",
    "    print(f\"\\n 질문: {question}\")\n",
    "    result = chain.invoke({\"question\": question})  # 최신 방식\n",
    "    answer = result[\"answer\"]\n",
    "    print(f\" 답변: {answer}\")\n",
    "    return answer\n",
    "\n",
    "# 질문들 실행\n",
    "questions = [\n",
    "    \"소년은 어디에서 처음 소녀를 만났나?\",\n",
    "    \"소년은 소녀에게 무엇을 주려고 했나?\", \n",
    "    \"그 장소는 어떤 특징이 있었나?\",\n",
    "    \"소나기는 언제 내렸나?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    answer = ask_question(conversation_chain, question)\n",
    "    if i < len(questions):\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
